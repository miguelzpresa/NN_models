{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbb1d08-bd3c-450d-ba07-4d3d6dc05a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
    "import fastai.vision.all as fv\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "import random\n",
    "from Layers import *\n",
    "from math import prod\n",
    "from PerceptualLoss import perceptual_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab91596f-f2a1-4e27-b963-af93f4b4f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DumbNoiser(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "        bs = x.shape[0]\n",
    "        alpha = torch.rand(bs,1,1,1,device=x.device)\n",
    "        noise = torch.randn_like(x)\n",
    "        return x*(1 - alpha) + noise*alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a08f48c-9f9a-46b7-a0e2-7d16aa6c5539",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeNoiser(nn.Module):\n",
    "    def __init__(self, max_num_steps = 75, scale=0.1):\n",
    "        super().__init__()\n",
    "        self.num_steps = max_num_steps\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self,x):\n",
    "        bs = x.shape[0]\n",
    "        \n",
    "        num_iters = random.randint(0, self.num_steps)\n",
    "        \n",
    "        noise = torch.randn(num_iters, *x.shape, device=x.device)\n",
    "        scale = torch.rand((1,bs,1,1,1),device=x.device)*self.scale\n",
    "        #print(f\"{num_iters}, {scale}\")\n",
    "        return x+(noise*scale).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c574e-9559-4124-b153-b4a7fde860fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlurNoiser(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "        f = random.choice([2,4])\n",
    "        ds = F.interpolate(x,scale_factor=1/f)\n",
    "        return F.interpolate(ds,scale_factor=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26939454-2233-4adb-86d2-b202b62dc72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectCombinator(nn.Module):\n",
    "    def __init__(self, modules):\n",
    "        super().__init__()\n",
    "        self.M = nn.ModuleList(modules)\n",
    "       \n",
    "    def forward(self,x):\n",
    "        results = torch.stack([m(x) for m in self.M])\n",
    "        n,bs,c,w,h = results.shape\n",
    "        \n",
    "        mask = torch.randint(0, 3, (bs,), device=x.device)\n",
    "        return results[mask,torch.arange(bs, device=x.device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e6672-d5f6-4df3-8439-d3afc8454455",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvexCombinator(nn.Module):\n",
    "    def __init__(self, modules):\n",
    "        super().__init__()\n",
    "        self.M = nn.ModuleList(modules)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        results = torch.stack([m(x) for m in self.M])\n",
    "        n = results.shape[0]\n",
    "        convex_conv = torch.softmax(torch.randn(n,1,1,1,1,device=x.device)*2,dim=0)\n",
    "        return (convex_conv*results).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786517d-bfee-46d4-91b9-78750b18d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tonto(x):\n",
    "    return 2*x - 1\n",
    "    \n",
    "def desnormalize_tonto(x):\n",
    "    return 0.5*(x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a5f8b-50f5-479a-96bd-818b7e74b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = fv.PILImage.create(\"facesM/25_1_00266.jpg\")\n",
    "x = normalize_tonto(to_tensor(f)[None])\n",
    "y = ConvexCombinator([IterativeNoiser(),DumbNoiser()])(x)\n",
    "to_pil_image(torch.clamp(desnormalize_tonto(y[0]),0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eea793-be61-4f2c-90b9-55383b684730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_params(m):\n",
    "    return sum([prod(p.shape) for p in m.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd89f64-292f-4157-baf6-b57a1631440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.randn(2,3,16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7c465d-bca5-4307-a305-98dd6037ed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#U(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ffbb55-a9b5-439b-9312-8d951c093566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age(f:Path):\n",
    "    l = f.stem.split(\"_\")\n",
    "    return float(l[0])\n",
    "\n",
    "def get_cat(f:Path):\n",
    "    l = f.stem.split(\"_\")\n",
    "    return l[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d99e29e-ef9c-45be-b3d9-0273b7086977",
   "metadata": {},
   "outputs": [],
   "source": [
    "edades = torch.tensor([get_age(f) for f in fv.get_image_files('facesM')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f6e0e-4e14-4aaa-9d05-629df12bc1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "edades_mean = edades.mean()\n",
    "edades_std = edades.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b35fbca-1926-467d-8af2-b2652f9c0791",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self, encoder_blocks, decoder_blocks, fea_proc):\n",
    "        super().__init__()\n",
    "        self.EB = nn.ModuleList(encoder_blocks)\n",
    "        self.DB = nn.ModuleList(decoder_blocks)\n",
    "        self.fea_proc = fea_proc\n",
    "\n",
    "    def forward(self, x, edad, cat):\n",
    "        proc = self.fea_proc(edad, cat)\n",
    "        x = torch.cat((x,proc),dim=1)\n",
    "        resultados_parciales = [x]\n",
    "        for e in self.EB:\n",
    "            x = e(x)\n",
    "            resultados_parciales.append(x)\n",
    "        for d,rp in zip(self.DB,resultados_parciales[::-1]):\n",
    "            bs,c,h,w = x.shape\n",
    "            faltan = c-rp.shape[1]\n",
    "            if faltan > 0: \n",
    "                rp = torch.cat([rp,torch.zeros(bs,faltan,h,w,device=x.device)],dim=1)\n",
    "            x = d(x+rp)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234b1341-ffd4-4249-ae5d-6d02118456af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Noisy_Unet(nn.Module):\n",
    "    def __init__ (self,encoder,Unet):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.Unet = Unet\n",
    "        self.Noiser = SelectCombinator([DumbNoiser(), IterativeNoiser()])\n",
    "        self.PrewarNoiser = ConvexCombinator([DumbNoiser(), IterativeNoiser(30,0.08), BlurNoiser()])\n",
    "        \n",
    "    def forward(self, x, edad, cat):\n",
    "        x = self.PrewarNoiser(x)\n",
    "        return self.Unet(self.Noiser(self.encoder(x)), edad, cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03b5418-5bf0-43a7-aac9-9ea0eca07282",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesProcessor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Emb = nn.Embedding(num_embeddings=2,embedding_dim=3)\n",
    "        self.Nn = nn.Sequential(\n",
    "                    nn.Linear(4,64),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.BatchNorm1d(64),\n",
    "                    nn.Linear(64,2*4*4),\n",
    "        )\n",
    "    \n",
    "    def forward(self,edad,cat):\n",
    "        bs = edad.shape[0]\n",
    "        edad = (edad - edades_mean)/edades_std\n",
    "        cat = self.Emb(cat)\n",
    "        a = torch.cat((edad[:,None],cat), dim = 1)\n",
    "        b = self.Nn(a)\n",
    "        b = b.reshape(bs,2,4,4)\n",
    "        return F.interpolate(b,scale_factor=8,mode='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6efbe61-c105-4a22-9fbb-b73c6e030392",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_blocks = [\n",
    "    nn.Sequential(\n",
    "        ResBlock(5,64),\n",
    "        ResBlock(64),\n",
    "        nn.BatchNorm2d(64),\n",
    "        SelfAttention(64),\n",
    "        ResBlock(64),\n",
    "        ResBlock(64),\n",
    "        nn.BatchNorm2d(64),\n",
    "        *cab(64,128, s=2, k=2)\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        ResBlock(128),\n",
    "        ResBlock(128),\n",
    "        nn.BatchNorm2d(128),\n",
    "        SelfAttention(128),\n",
    "        ResBlock(128),\n",
    "        ResBlock(128),\n",
    "        nn.BatchNorm2d(128),\n",
    "        *cab(128,256, s=2, k=2)\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        ResBlock(256),\n",
    "        ResBlock(256,),\n",
    "        nn.BatchNorm2d(256),\n",
    "        SelfAttention(256),\n",
    "        ResBlock(256,g=2),\n",
    "        ResBlock(256),\n",
    "        nn.BatchNorm2d(256),\n",
    "        *cab(256,384, s=2, k=2)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1008a3d0-6290-4ac8-83b6-91e6b651297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_blocks = [\n",
    "    nn.Sequential(\n",
    "        ResBlock(384,g=2),\n",
    "        ResBlock(384,g=2),\n",
    "        nn.BatchNorm2d(384),\n",
    "        SelfAttention(384),\n",
    "        ResBlock(384,g=2),\n",
    "        ResBlock(384,g=2),\n",
    "        fv.PixelShuffle_ICNR(384,256)\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        ResBlock(256),\n",
    "        ResBlock(256),\n",
    "        nn.BatchNorm2d(256),\n",
    "        SelfAttention(256),\n",
    "        ResBlock(256),\n",
    "        ResBlock(256),\n",
    "        fv.PixelShuffle_ICNR(256,128)\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        ResBlock(128),\n",
    "        ResBlock(128),\n",
    "        nn.BatchNorm2d(128),\n",
    "        SelfAttention(128),\n",
    "        ResBlock(128),\n",
    "        ResBlock(128),\n",
    "        fv.PixelShuffle_ICNR(128,64)\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        ResBlock(64),\n",
    "        ResBlock(64),\n",
    "        nn.BatchNorm2d(64),\n",
    "        SelfAttention(64),\n",
    "        ResBlock(64),\n",
    "        ResBlock(64),\n",
    "        conv2d(64,3)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f5083a-d777-4667-be39-b3383964facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = Unet(encoder_blocks, decoder_blocks, FeaturesProcessor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c49468-3546-4f49-84c0-e9351fd270a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ed077-cf3a-443f-b88d-308c66418032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder, img_size, batch_size):\n",
    "    tfms = fv.aug_transforms()\n",
    "        \n",
    "    data = fv.DataBlock(blocks = (fv.ImageBlock, fv.RegressionBlock, fv.CategoryBlock, fv.ImageBlock),\n",
    "                        n_inp = 3,\n",
    "                        get_items = fv.get_image_files,\n",
    "                        getters   = [lambda x: x, get_age, get_cat, lambda x: x],\n",
    "                        splitter  = fv.RandomSplitter(.05,seed = 666),\n",
    "                        item_tfms = fv.Resize(img_size),\n",
    "                        batch_tfms= tfms,\n",
    "                     )\n",
    "    return data.dataloaders(folder, bs=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2180f803-61b5-4345-8ed9-6ee5d315f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = load_data(\"facesM\", 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3735c65b-d2e7-4afc-8864-38c4588e77eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder import create_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca47cd-7936-4913-a1f7-3e2636709336",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = create_autoencoder().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba514610-1e6d-4e48-aa6b-2cbaaddbfc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_dict = torch.load('models/Perceptual.pth')['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1771a0-8cec-4f4e-8477-5d3b5e770351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A.load_state_dict(autoencoder_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f2087-a077-42dc-bc14-bd4735c8a2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in A.parameters():\n",
    "    p.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9466d29-7a03-44fe-ad2d-bea11ef313c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.randn(1,3,32,32)\n",
    "#A.eval().cpu()\n",
    "#img_de_latente_aleatorio = A.decoder(x)\n",
    "\n",
    "#to_pil_image(img_de_latente_aleatorio[0].clamp(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7358a95-0b30-476e-b5e7-83861241ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = fv.PILImage.create(\"facesM/30_1_28985.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ae693-ba2f-44fc-95bb-28e10cadedee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.encoder(to_tensor(f)[None]).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2874c38-d9f9-44a2-99ce-c4268044b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4879fa87-5224-40fe-9eeb-aabb32f5f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Noisy_Unet(A.encoder,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dfc259-50f8-40d6-b24b-1974ac778fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_latente(yp, y):\n",
    "    y = A.encoder(y)\n",
    "    return F.smooth_l1_loss(yp, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c0b234-62b8-4473-97ba-8ba8e81f618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = fv.Learner(dls,model,\n",
    "                   loss_func = mse_latente,\n",
    "                   opt_func = fv.ranger,\n",
    "                   wd=0.05,\n",
    "                   wd_bn_bias = True,\n",
    "                   cbs=[fv.GradientClip(0.2), fv.SaveModelCallback(fname='UNET_it')]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2dd2c4-c0d6-4a53-aa36-514bf3e1bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.load(\"UNET_perceptual_finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f6ea4-b2ec-432b-bbc4-f181bdfb1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7ec73-9f4d-4e4c-bdcb-f71cabd06b27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(40,1e-2,div=0.95,pct_start=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faedbb44-a3d0-404f-9de5-3c17a8321060",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"UNET_it_finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d539113-1e93-4f00-926d-9300c52825d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ploss = perceptual_loss().cuda()\n",
    "def mse_latente_perceptual(yp_l, y):\n",
    "    y_l = A.encoder(y)\n",
    "    yp = A.decoder(yp_l)\n",
    "    return 16*F.smooth_l1_loss(yp_l, y_l) + ploss(yp,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e2fec6-ca3d-46ec-a017-6b9ab89847f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = mse_latente_perceptual\n",
    "learn.dls.train.bs = 16\n",
    "learn.dls.valid.bs = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4035df76-759e-4f6d-a484-3b873e576f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(30,7e-4,div=0.95,pct_start=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7640141c-de62-4de2-afa7-fb8a234f53ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"UNET_finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787edf77-1824-42ad-a70c-e2bcb221deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.load(\"UNET_it_perceptual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e51bd8-f4cf-4930-9840-926392d5f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choice(alumnos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff318aed-a484-47dd-9a5d-e0b763843388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import HTML, display\n",
    "import io\n",
    "import base64\n",
    "\n",
    "def display_gif(image_list, duration=100, loop=0):\n",
    "    buffer = io.BytesIO()\n",
    "\n",
    "    image_list[0].save(buffer, format='GIF', save_all=True, append_images=image_list[1:], duration=duration, loop=loop)\n",
    "\n",
    "    buffer.seek(0)\n",
    "    gif_data = base64.b64encode(buffer.read()).decode('ascii')\n",
    "\n",
    "    display(HTML(f'<img src=\"data:image/gif;base64,{gif_data}\">'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7d0d3b-92cd-4a13-bbda-3090b7954dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "U.eval().cpu()\n",
    "A.eval().cpu()\n",
    "x = torch.randn(1,3,32,32)\n",
    "edad = torch.tensor([4])\n",
    "cat = torch.tensor([1])\n",
    "images = [to_pil_image(A.decoder(x)[0])]\n",
    "steps = 20\n",
    "for i in range(steps):\n",
    "    p = U(x,edad,cat)\n",
    "    faltan = steps - i\n",
    "    x = p/faltan + x*(faltan - 1)/faltan\n",
    "    img = torch.clamp(A.decoder(x)[0],0,1)\n",
    "    images.append(to_pil_image(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df7c5f-a001-4453-820a-d3bd6d23c630",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_gif(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717b88c4-6014-4ecf-b1e0-36b588d833cd",
   "metadata": {},
   "source": [
    "## Cambios que hice:\n",
    "\n",
    "- Agregué capas de self attention a la UNET\n",
    "- Creé el IterativeNoise, que en vez de agregar ruido una vez, lo hace varias veces (pero en cada una poquito ruido), porque así funciona el stable diffusion, no como lo habíamos hecho\n",
    "- Combiné ambos ruidos. En cada imagen toma uno de los dos ruidos aleatoriamente (yo siento que tener más tipos de ruido lo hace mejor)\n",
    "- Agregué los callbacks: SaveModel, GradientClipping, Weight Decay.\n",
    "- Entrené 100 epochs. YOLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096bd488-a9d1-4ef3-9f1f-f0343ec8b61c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
